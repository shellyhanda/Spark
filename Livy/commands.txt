*************--Working commands and their results------************ 
Livy offers a wrapper around spark-submit that work with jar and py files. The API is slightly different than the interactive

-----------------------------------------
 curl --negotiate -u svchdphdo4ecfd -H 'X-Requested-By:svchdphdo4ecfd' -X POST --data '{"file": "hdfs:///dev/ecfd/python_poc/hello.py"}' -H "Content-Type: application/json" https://hdo4241-23.ca.boeing.com:8999/batches
 ==>
 Enter host password for user 'svchdphdo4ecfd':
{"id":38,"state":"starting","appId":null,"appInfo":{"driverLogUrl":null,"sparkUiUrl":null},"log":["stdout: ","\nstderr: ","\nYARN Diagnostics: "]}
svchdphdo4ecfd@hdo4241-23:~>
svchdphdo4ecfd@hdo4241-23:~>
----------------------------------------------
curl --negotiate -u svchdphdo4ecfd -H 'X-Requested-By:svchdphdo4ecfd' https://hdo4241-23.ca.boeing.com:8999/batches/38 | python -m json.tool
==>
svchdphdo4ecfd@hdo4241-23:~> curl --negotiate -u svchdphdo4ecfd -H 'X-Requested-By:svchdphdo4ecfd' https://hdo4241-23.ca.boeing.com:8999/batches/38 | python -m json.tool
Enter host password for user 'svchdphdo4ecfd':
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   302  100   302    0     0  20526      0 --:--:-- --:--:-- --:--:-- 21571
100   917  100   917    0     0  54505      0 --:--:-- --:--:-- --:--:-- 54505
{
    "appId": "application_1544487375083_12274",
    "appInfo": {
        "driverLogUrl": "http://hdo4240-2.ca.boeing.com:8188/applicationhistory/logs/hdo4240-9.ca.boeing.com:45454/container_e174_1544487375083_12274_01_000001/container_e174_1544487375083_12274_01_000001/svchdphdo4ecfd",
        "sparkUiUrl": "http://hdo4240-4.ca.boeing.com:8088/proxy/application_1544487375083_12274/"
    },
    "id": 38,
    "log": [
        "\t queue: ecfd",
        "\t start time: 1545084952950",
        "\t final status: UNDEFINED",
        "\t tracking URL: http://hdo4240-4.ca.boeing.com:8088/proxy/application_1544487375083_12274/",
        "\t user: svchdphdo4ecfd",
        "18/12/17 14:15:52 INFO ShutdownHookManager: Shutdown hook called",
        "18/12/17 14:15:52 INFO ShutdownHookManager: Deleting directory /tmp/spark-244c4724-7c63-4589-aed4-83d68edfe3d2",
        "18/12/17 14:15:52 INFO ShutdownHookManager: Deleting directory /tmp/spark-e27a0486-4496-4ef1-b274-915fcbe4d4f8",
        "\nstderr: ",
        "\nYARN Diagnostics: "
    ],
    "state": "success"
}
svchdphdo4ecfd@hdo4241-23:~>
-------------------------------------------------
curl --negotiate -u svchdphdo4ecfd -H 'X-Requested-By:svchdphdo4ecfd' https://hdo4241-23.ca.boeing.com:8999/batches/38/log |  python -m json.tool

==>
svchdphdo4ecfd@hdo4241-23:~> curl --negotiate -u svchdphdo4ecfd -H 'X-Requested-By:svchdphdo4ecfd' https://hdo4241-23.ca.boeing.com:8999/batches/38/log |  python -m json.tool
Enter host password for user 'svchdphdo4ecfd':
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   306  100   306    0     0  17048      0 --:--:-- --:--:-- --:--:-- 18000
100  5150  100  5150    0     0   117k      0 --:--:-- --:--:-- --:--:--     0
{
    "from": 0,
    "id": 38,
    "log": [
        "stdout: ",
        "Warning: Master yarn-cluster is deprecated since 2.0. Please use master \"yarn\" with specified deploy mode instead.",
        "18/12/17 14:15:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable",
        "18/12/17 14:15:48 WARN DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.",
        "18/12/17 14:15:49 INFO RequestHedgingRMFailoverProxyProvider: Looking for the active RM in [rm1, rm2]...",
        "18/12/17 14:15:49 INFO RequestHedgingRMFailoverProxyProvider: Found active RM [rm2]",
        "18/12/17 14:15:49 INFO Client: Requesting a new application from cluster with 27 NodeManagers",
        "18/12/17 14:15:49 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (393216 MB per container)",
        "18/12/17 14:15:49 INFO Client: Will allocate AM container, with 2432 MB memory including 384 MB overhead",
        "18/12/17 14:15:49 INFO Client: Setting up container launch context for our AM",
        "18/12/17 14:15:49 INFO Client: Setting up the launch environment for our AM container",
        "18/12/17 14:15:49 INFO Client: Preparing resources for our AM container",
        "18/12/17 14:15:49 INFO HadoopFSDelegationTokenProvider: getting token for: DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_4139782_1, ugi=svchdphdo4ecfd (auth:PROXY) via livy/hdo4241-23.ca.boeing.com@NOS.BOEING.COM (auth:KERBEROS)]]",
        "18/12/17 14:15:50 INFO DFSClient: Created HDFS_DELEGATION_TOKEN token 817108 for svchdphdo4ecfd on ha-hdfs:BOEINGHDO4",
        "18/12/17 14:15:50 WARN HiveConf: HiveConf of name hive.server2.http.endpoint does not exist",
        "18/12/17 14:15:50 WARN HiveConf: HiveConf of name hive.server2.http.endpoint does not exist",
        "18/12/17 14:15:50 WARN HiveConf: HiveConf of name hive.server2.http.endpoint does not exist",
        "18/12/17 14:15:50 INFO metastore: Trying to connect to metastore with URI thrift://hdo4240-2.ca.boeing.com:9083",
        "18/12/17 14:15:50 INFO metastore: Connected to metastore.",
        "18/12/17 14:15:52 INFO Client: Use hdfs cache file as spark.yarn.archive for HDP, hdfsCacheFile:hdfs://BOEINGHDO4/hdp/apps/2.6.5.0-292/spark2/spark2-hdp-yarn-archive.tar.gz",
        "18/12/17 14:15:52 INFO Client: Source and destination file systems are the same. Not copying hdfs://BOEINGHDO4/hdp/apps/2.6.5.0-292/spark2/spark2-hdp-yarn-archive.tar.gz",
        "18/12/17 14:15:52 INFO Client: Source and destination file systems are the same. Not copying hdfs:/dev/ecfd/python_poc/hello.py",
        "18/12/17 14:15:52 INFO Client: Uploading resource file:/usr/hdp/current/spark2-client/python/lib/pyspark.zip -> hdfs://BOEINGHDO4/user/svchdphdo4ecfd/.sparkStaging/application_1544487375083_12274/pyspark.zip",
        "18/12/17 14:15:52 INFO Client: Uploading resource file:/usr/hdp/current/spark2-client/python/lib/py4j-0.10.6-src.zip -> hdfs://BOEINGHDO4/user/svchdphdo4ecfd/.sparkStaging/application_1544487375083_12274/py4j-0.10.6-src.zip",
        "18/12/17 14:15:52 INFO Client: Uploading resource file:/tmp/spark-244c4724-7c63-4589-aed4-83d68edfe3d2/__spark_conf__4505135534719326578.zip -> hdfs://BOEINGHDO4/user/svchdphdo4ecfd/.sparkStaging/application_1544487375083_12274/__spark_conf__.zip",
        "18/12/17 14:15:52 INFO SecurityManager: Changing view acls to: livy,svchdphdo4ecfd",
        "18/12/17 14:15:52 INFO SecurityManager: Changing modify acls to: livy,svchdphdo4ecfd",
        "18/12/17 14:15:52 INFO SecurityManager: Changing view acls groups to: ",
        "18/12/17 14:15:52 INFO SecurityManager: Changing modify acls groups to: ",
        "18/12/17 14:15:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(livy, svchdphdo4ecfd); groups with view permissions: Set(); users  with modify permissions: Set(livy, svchdphdo4ecfd); groups with modify permissions: Set()",
        "18/12/17 14:15:52 INFO Client: Submitting application application_1544487375083_12274 to ResourceManager",
        "18/12/17 14:15:52 INFO YarnClientImpl: Submitted application application_1544487375083_12274",
        "18/12/17 14:15:52 INFO Client: Application report for application_1544487375083_12274 (state: ACCEPTED)",
        "18/12/17 14:15:52 INFO Client: ",
        "\t client token: N/A",
        "\t diagnostics: [Mon Dec 17 14:15:52 -0800 2018] Application is Activated, waiting for resources to be assigned for AM.  Details : AM Partition = <DEFAULT_PARTITION> ; Partition Resource = <memory:10616832, vCores:1512> ; Queue's Absolute capacity = 15.000001 % ; Queue's Absolute used capacity = 0.05787037 % ; Queue's Absolute max capacity = 60.000004 % ; ",
        "\t ApplicationMaster host: N/A",
        "\t ApplicationMaster RPC port: -1",
        "\t queue: ecfd",
        "\t start time: 1545084952950",
        "\t final status: UNDEFINED",
        "\t tracking URL: http://hdo4240-4.ca.boeing.com:8088/proxy/application_1544487375083_12274/",
        "\t user: svchdphdo4ecfd",
        "18/12/17 14:15:52 INFO ShutdownHookManager: Shutdown hook called",
        "18/12/17 14:15:52 INFO ShutdownHookManager: Deleting directory /tmp/spark-244c4724-7c63-4589-aed4-83d68edfe3d2",
        "18/12/17 14:15:52 INFO ShutdownHookManager: Deleting directory /tmp/spark-e27a0486-4496-4ef1-b274-915fcbe4d4f8",
        "\nstderr: ",
        "\nYARN Diagnostics: "
    ],
    "total": 48
}

----------------------------------------------------------
curl --negotiate -u svchdphdo4ecfd -H 'X-Requested-By:svchdphdo4ecfd' https://hdo4241-23.ca.boeing.com:8999/sessions | python -m json.tool 
==>
svchdphdo4ecfd@hdo4241-23:~> curl --negotiate -u svchdphdo4ecfd -H 'X-Requested-By:svchdphdo4ecfd' https://hdo4241-23.ca.boeing.com:8999/sessions | python -m json.tool
Enter host password for user 'svchdphdo4ecfd':
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   300  100   300    0     0  16981      0 --:--:-- --:--:-- --:--:-- 17647
100    34  100    34    0     0   1721      0 --:--:-- --:--:-- --:--:--  1721
{
    "from": 0,
    "sessions": [],
    "total": 0
}
----------------------------------------------------------------------------------------------------------------
yarn logs -applicationId  application_1544487375083_12274 > Python_17Dec.out